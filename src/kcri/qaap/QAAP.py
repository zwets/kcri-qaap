#!/usr/bin/env python3
#
# QAAP.py - main for the KCRI Assembly and Quality Analysis Pipeline
#

import sys, os, argparse, json
from pico.workflow.logic import Workflow
from pico.workflow.executor import Executor
from pico.jobcontrol.subproc import SubprocessScheduler
from .data import QAAPBlackboard
from .services import SERVICES
from .workflow import DEPENDENCIES
from .workflow import SystemTargets, UserTargets, Services, Params
from .filescan import detect_filetype, scan_inputs, find_inputs, symlink_input_pairs, symlink_input_files
from . import __version__

# Global variables and defaults
SERVICE, VERSION = "KCRI QAAP", __version__

# Exit with error message and non-zero code
def err_exit(msg, *args):
    print(('QAAP: %s' % msg) % args, file=sys.stderr)
    sys.exit(1)

# Parse string to UserTarget or Service, else raise error
def UserTargetOrService(s):
    try: return UserTargets(s)
    except: return Services(s)


# MAIN -------------------------------------------------------------------

def main():
    '''QAAP main program.'''

    parser = argparse.ArgumentParser(
        description="""\
The KCRI Quality Analysis and Assembly Pipeline (QAAP) performs quality
analysis and assembly of sequencer reads.  It executes a workflow of tool
invocations depending on the targets it is given.

The actions to be performed are specified using the -t/--targets option.
Each target corresponds to a recipe for a series of service invocations.
When omitted, the DEFAULT target is assumed.

Use -l/--list-targets to see available TARGETS.  Use -s/--list-services
to see available SERVICES.  Combine -t DEFAULT with -x/--exclude to stop
specific targets or services from being executed.

INPUTS to the QAAP can currently be either:
- A MiSeq run output directory.  QAAP will process all reads in that run,
  and analyses the 'InterOp' data produced by the MiSeq for QC.
- An arbitrary directory with fastqs or FASTAs.  QAAP will process all
  fastq and/or FASTA files in the directory, depending on target/recipe.
- A list of fastq and/or FASTA files, which will likewise be processed
  according to target/recipe.

QAAP automatically pairs up PAIRED-END reads, provided file names differ
in exactly one position, where one file has a '1' and the other a '2',
following an R, r, -, _, ., or @.

OUTPUT is generated in directories under OUT_DIR.  Sample names are
generated by removing extensions and other gunk from file names.
""",
        epilog="""\
Instead of passing arguments on the command-line, you can put them, one
per line, in a text file and pass this file with @FILENAME.
""",
        fromfile_prefix_chars='@',
        formatter_class=argparse.RawDescriptionHelpFormatter)

    # General arguments
    group = parser.add_argument_group('General parameters')
    group.add_argument('-t', '--targets',       metavar='TARGET[,...]', default='DEFAULT', help="analyses to perform [DEFAULT]")
    group.add_argument('-x', '--exclude',       metavar='TARGET_OR_SERVICE[,...]', help="targets and/or services to exclude from running")
    group.add_argument('-o', '--out-dir',       metavar='PATH', default='.', help="base directory to write output to [PWD] (must be relative when dockerised)")
    group.add_argument('-m', '--metagenomic',   action='store_true', help="specifies that the run is metagenomic")
    group.add_argument('-a', '--amplicon',      action='store_true', help="specifies that the run is (metagenomic) amplicon")
    group.add_argument('-l', '--list-targets',  action='store_true', help="list the available targets")
    group.add_argument('-s', '--list-services', action='store_true', help="list the available services")
    group.add_argument('-r', '--reference',     metavar='FASTA', help="path to a reference genome to use for assembly QC")
    group.add_argument('-d', '--db-root',       metavar='PATH', default='/databases', help="base path to databases (leave default when dockerised)")
    group.add_argument('-v', '--verbose',       action='store_true', help="write verbose output to stderr")
    group.add_argument('inputs', metavar='DIR_OR_FILES', nargs='*', default=[], help="input directory or list of fastq files")

    # Resource management arguments
    group = parser.add_argument_group('Scheduler parameters')
    group.add_argument('--max-cpus', metavar='N',   type=int, default=None, help="number of CPUs to allocate (default: all but 2)")
    group.add_argument('--max-mem',  metavar='GB',  type=int, default=None, help="total memory to allocate (default: 90%%)")
    group.add_argument('--max-disc', metavar='GB',  type=int, default=None, help="total disc space to allocate (default: 80%%)")
    group.add_argument('--max-time', metavar='SEC', type=int, default=None, help="maximum overall run time (default: unlimited)")
    group.add_argument('--poll',     metavar='SEC', type=int, default=2, help="seconds between backend polls [2]")

    # Service specific arguments
#    group = parser.add_argument_group('Sequencing specs')
#    group.add_argument('--sq-p', metavar='PLATFORM', help='sequencing platform (%s)' % ','.join(v.value for v in SeqPlatform))
#    group.add_argument('--sq-r', metavar='PAIRING', help='pairing of reads (%s; default: %s when two fastqs are passed, unpaired when one)' % (', '.join(v.value for v in SeqPairing), SeqPairing.PAIRED.value))
    group = parser.add_argument_group('Trimming parameters')
    group.add_argument('--tr-q', type=int, metavar='Q', default=None, help="cut-off Q score (default: 10 regular, 20 metagenomic)")
    group.add_argument('--tr-l', type=int, metavar='LEN', default=None, help="minimum read length to keep (default: 36 regular, 72 metagenomic)")
    group.add_argument('--tr-a', metavar='NAME', default=None, help="base name of the Trimmomatic adapter file [default], -{PE.SE}.fa will be appended")
    group = parser.add_argument_group('Quast parameters')
    group.add_argument('--qu-t', type=int, metavar='LEN', default=500, help="threshold contig length for Quast (500)")

    # Perform the parsing
    args = parser.parse_args()

    # Parse targets and translate to workflow arguments
    targets = []
    try:
        targets = list(map(lambda t: UserTargets(t.strip()), args.targets.split(',') if args.targets else []))
    except ValueError as ve:
        err_exit('invalid target: %s (try --list-targets)', ve)

    # Parse excludes and translate to workflow arguments
    excludes = []
    try:
        excludes = list(map(lambda t_or_s: UserTargetOrService(t_or_s.strip()), args.exclude.split(',') if args.exclude else []))
    except ValueError as ve:
        err_exit('invalid exclude: %s (try --list-targets and --list-services)', ve)

    # Parse and validate inputs into fastqs and fastas
    illumina_run_dir = None
    il_fqs = dict()     # illumina pe reads
    pe_fqs = dict()     # other pe reads
    se_fqs = dict()     # single reads
    fastas = dict()     # fasta files
    if len(args.inputs) == 1 and os.path.isdir(args.inputs[0]):
        inp_dir = args.inputs[0]
        if is_illumina_run_dir(inp_dir):
            illumina_run_dir = os.path.abspath(inp_dir)
            inp_dir = os.path.join(inp_dir, 'Data','Intensities','BaseCalls')
            il_fqs, _, _, _ = find_inputs(inp_dir)
            if not il_fqs:
                err_exit('no reads found in miseq run dir: %s' % inp_dir)
        else:
            il_fqs, pe_fqs, se_fqs, fastas = find_inputs(inp_dir)
    elif args.inputs:
        il_fqs, pe_fqs, se_fqs, fastas = scan_inputs(args.inputs, strict=True)

    # Parse the reference parameter
    reference = None
    if args.reference:
        if not os.path.isfile(args.reference):
            err_exit('no such file: %s', args.reference)
        if detect_filetype(args.reference) != 'fasta':
            err_exit('reference not a FASTA file: %s', args.reference)
        reference = os.path.abspath(args.reference)

    # Parse the --list options
    if args.list_targets:
        print('targets:', ','.join(t.value for t in UserTargets))
    if args.list_services:
        print('services:', ','.join(s.value for s in Services))

    # Exit when no inputs were provided
    if not args.inputs:
        if not args.list_targets and not args.list_services:
            err_exit('no inputs were provided')
        else:
            sys.exit(0)

    # Check existence of the db_root directory
    if not os.path.isdir(args.db_root):
        err_exit('no such directory for --db-root: %s', args.db_root)
    db_root = os.path.abspath(args.db_root)

    # Create the output directory, with inside the inputs directory
    try:
        inputs_dir = os.path.join(args.out_dir,'inputs')
        os.makedirs(inputs_dir, exist_ok=True)
    except Exception as e:
        err_exit('error creating directory %s: %s', inputs_dir, str(e))

    # Put symlinks to the inputs in the out-dir-relative inputs directory
    il_fqs = symlink_input_pairs(inputs_dir, il_fqs)
    pe_fqs = symlink_input_pairs(inputs_dir, pe_fqs)
    se_fqs = symlink_input_files(inputs_dir, se_fqs, '.fq')
    fastas = symlink_input_files(inputs_dir, fastas, '.fa')

    # Now that path handling has been done we can safely change our PWD
    os.chdir(args.out_dir)

    # Set up the Workflow execution
    blackboard = QAAPBlackboard(args.verbose)
    blackboard.start_run(SERVICE, VERSION, vars(args))
    blackboard.put_illumina_run_dir(illumina_run_dir)
    blackboard.put_db_root(db_root)

    # Set the workflow params based on user inputs present
    params = list()
    if il_fqs:
        params.append(Params.MISEQ_READS)
        params.append(Params.READS)
        blackboard.put_input_il_fqs(il_fqs)
    if pe_fqs:
        params.append(Params.READS)
        blackboard.put_input_pe_fqs(pe_fqs)
    if se_fqs:
        params.append(Params.READS)
        blackboard.put_input_se_fqs(se_fqs)
    if fastas:
        params.append(Params.FASTAS)
        blackboard.put_input_fastas(fastas)

    # Set up the workflow executor and the batches
    scheduler = SubprocessScheduler(args.max_cpus, args.max_mem, args.max_disc, args.max_time, args.poll, not args.verbose)
    executor = Executor(SERVICES, scheduler)
    workflow = Workflow(DEPENDENCIES, params, targets, excludes)
    executor.execute(workflow, blackboard)
    workflow = Workflow(DEPENDENCIES, params, [SystemTargets.MULTIQC], excludes)
    executor.execute(workflow, blackboard)

    # DONE, mark the end of the run end on the blackboard
    blackboard.end_run()

    # Dump the blackboard to the JSON results file
    with open('qaap-results.json', 'w') as f_json:
        json.dump(blackboard.as_dict(args.verbose), f_json)

    # Write a TSV summary?
    with open('qaap-summary.tsv', 'w') as f_tsv:
        commasep = lambda l: ','.join(l) if l else ''
        b = blackboard
        d = dict({
            's_id': 'TODO',
            'n_reads': b.get('services/ReadsMetrics/results/n_reads', 'NA'),
            'nt_read': b.get('services/ReadsMetrics/results/n_bases', 'NA'),
            'pct_q30': b.get('services/ReadsMetrics/results/pct_q30', 'NA'),
            'n_ctgs': b.get('services/ContigsMetrics/results/n_seqs', 'NA'),
            'nt_ctgs': b.get('services/ContigsMetrics/results/tot_len', 'NA'),
            'n1':  b.get('services/ContigsMetrics/results/max_len', 'NA'),
            'n50':  b.get('services/ContigsMetrics/results/n50', 'NA'),
            'l50':  b.get('services/ContigsMetrics/results/l50', 'NA'),
            'pct_gc':  b.get('services/ContigsMetrics/results/pct_gc', b.get('services/ReadsMetrics/results/pct_gc', 'NA')),
            })
        print('\t'.join(d.keys()), file=f_tsv)
        print('\t'.join(map(lambda v: v if v else '', d.values())), file=f_tsv)

    # Done done
    return 0


if __name__ == '__main__':
   main()

