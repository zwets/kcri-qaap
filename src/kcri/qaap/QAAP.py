#!/usr/bin/env python3
#
# QAAP.py - main for the KCRI Assembly and Quality Analysis Pipeline
#

import sys, os, argparse, json
from pico.workflow.logic import Workflow
from pico.workflow.executor import Executor
from pico.jobcontrol.subproc import SubprocessScheduler
from .data import QAAPBlackboard
from .services import SERVICES
from .workflow import DEPENDENCIES
from .workflow import SystemTargets, UserTargets, Services, Params
from .filescan import detect_filetype, scan_inputs, find_inputs, is_miseq_output_dir
from . import __version__

# Global variables and defaults
SERVICE, VERSION = "KCRI QAAP", __version__

# Exit with error message and non-zero code
def err_exit(msg, *args):
    print(('QAAP: %s' % msg) % args, file=sys.stderr)
    sys.exit(1)

# Parse string to UserTarget or Service, else raise error
def UserTargetOrService(s):
    try: return UserTargets(s)
    except: return Services(s)


# MAIN -------------------------------------------------------------------

def main():
    '''QAAP main program.'''

    parser = argparse.ArgumentParser(
        description="""\
The KCRI Quality Analysis and Assembly Pipeline (QAAP) performs quality
analysis and assembly of sequencer reads.  It executes a workflow of tool
invocations depending on the targets it is given.

The actions to be performed are specified using the -t/--targets option.
Each target corresponds to a recipe for a series of service invocations.
When omitted, the DEFAULT target is assumed.

Use -l/--list-targets to see available TARGETS.  Use -s/--list-services
to see available SERVICES.  Combine -t DEFAULT with -x/--exclude to stop
specific targets or services from being executed.

INPUTS to the QAAP can currently be either:
- A MiSeq run output directory.  QAAP will process all reads in that run,
  and will analyse the 'InterOp' data produced by the MiSeq for QC.
- An arbitrary directory.  QAAP will process all fastq and/or FASTA files
  in the directory, depending on target/recipe.
- A list of fastq and/or FASTA files, which will likewise be processed
  according to target/recipe.

QAAP automatically pairs up PAIRED-END reads, provided file names differ
in exactly one position, where one file has a '1' and the other a '2'.

Per sample OUTPUT is written to directories under OUT_DIR.  Sample names
are generated by removing extensions and other gunk from file names.
""",
        epilog="""\
Instead of passing arguments on the command-line, you can put them, one
per line, in a text file and pass this file with @FILENAME.
""",
        fromfile_prefix_chars='@',
        formatter_class=argparse.RawDescriptionHelpFormatter)

    # General arguments
    group = parser.add_argument_group('General parameters')
    group.add_argument('-t', '--targets',  metavar='TARGET[,...]', default='DEFAULT', help="analyses to perform [DEFAULT]")
    group.add_argument('-x', '--exclude',  metavar='TARGET_OR_SERVICE[,...]', help="targets and/or services to exclude from running")
    group.add_argument('-m', '--meta',     action='store_true', help="specifies that the run is metagenomic")
    group.add_argument('-r', '--ref',      metavar='FASTA', help="path to a reference genome to use in assembly QC (Quast)")
    group.add_argument('-o', '--out-dir',  metavar='PATH', default='.', help="directory to write output to, default PWD (must be relative when dockerised)")
    group.add_argument('-l', '--list-targets',  action='store_true', help="list the available targets")
    group.add_argument('-s', '--list-services', action='store_true', help="list the available services")
    group.add_argument('-d', '--db-dir',  metavar='PATH', default='/databases', help="base path to databases required by some services (leave default when dockerised)")
    group.add_argument('-v', '--verbose', action='store_true', help="write verbose output to stderr")
    group.add_argument('inputs', metavar='DIR_OR_FILES', nargs='*', default=[], help="input directory or list of fastq files")

    # Resource management arguments
    group = parser.add_argument_group('Scheduler parameters')
    group.add_argument('--max-cpus',      metavar='N',   type=int, default=None, help="number of CPUs to allocate (default: all but 2)")
    group.add_argument('--max-mem',       metavar='GB',  type=int, default=None, help="total memory to allocate (default: 90%%)")
    group.add_argument('--max-disc',      metavar='GB',  type=int, default=None, help="total disc space to allocate (default: 80%%)")
    group.add_argument('--max-time',      metavar='SEC', type=int, default=None, help="maximum overall run time (default: unlimited)")
    group.add_argument('--poll', metavar='SEC', type=int, default=5, help="seconds between backend polls [5]")

    # Service specific arguments
#    group = parser.add_argument_group('Sequencing specs')
#    group.add_argument('--sq-p', metavar='PLATFORM', help='sequencing platform (%s)' % ','.join(v.value for v in SeqPlatform))
#    group.add_argument('--sq-r', metavar='PAIRING', help='pairing of reads (%s; default: %s when two fastqs are passed, unpaired when one)' % (', '.join(v.value for v in SeqPairing), SeqPairing.PAIRED.value))
    group = parser.add_argument_group('Trimming parameters')
    group.add_argument('--tr-q', type=int, metavar='Q', default=None, help="cut-off Q score (default: 10 regular, 20 metagenomic)")
    group.add_argument('--tr-l', type=int, metavar='LEN', default=None, help="minimum read length to keep (default: 36 regular, 72 metagenomic)")
    group.add_argument('--tr-a', metavar='NAME', default=None, help="base name of the Trimmomatic adapter file [default], -{PE.SE}.fa will be appended")
    group = parser.add_argument_group('Quast parameters')
    group.add_argument('--qu-t', type=int, metavar='LEN', default=500, help="threshold contig length for Quast (500)")

    # Perform the parsing
    args = parser.parse_args()

    # Parse targets and translate to workflow arguments
    targets = []
    try:
        targets = list(map(lambda t: UserTargets(t.strip()), args.targets.split(',') if args.targets else []))
    except ValueError as ve:
        err_exit('invalid target: %s (try --list-targets)', ve)

    # Parse excludes and translate to workflow arguments
    excludes = []
    try:
        excludes = list(map(lambda t_or_s: UserTargetOrService(t_or_s.strip()), args.exclude.split(',') if args.exclude else []))
    except ValueError as ve:
        err_exit('invalid exclude: %s (try --list-targets and --list-services)', ve)

    # Parse and validate inputs into fastqs and fastas
    miseq_run_dir = None
    single_fqs = dict()
    paired_fqs = dict()
    fastas = dict()
    if len(args.inputs) == 1 and os.path.isdir(args.inputs[0]):
        inp_dir = os.path.abspath(args.inputs[0])
        if is_miseq_output_dir(inp_dir):
            miseq_run_dir = inp_dir
            _, single_fqs, paired_fqs = find_inputs(
                os.path.join(miseq_run_dir,'Data').join('Intensities').join('BaseCalls'))
            if single_fqs:
                err_exit('unpaired fastqs found in MiSeq run: %s', str(single_fqs))
        else:
            fastas, single_fqs, paired_fqs = find_inputs(inp_dir)
    elif args.inputs:
        fastas, single_fqs, paired_fqs = scan_inputs(args.inputs, strict=True)

    # Parse the ref parameter
    reference = None
    if args.ref:
        if not os.path.isfile(args.ref):
            err_exit('no such file: %s', args.ref)
        if detect_filetype(args.ref) != 'fasta':
            err_exit('reference not a FASTA file: %s', args.ref)
        reference = os.path.abspath(args.ref)

    # Parse the --list options
    if args.list_targets:
        print('targets:', ','.join(t.value for t in UserTargets))
    if args.list_services:
        print('services:', ','.join(s.value for s in Services))

    # Exit when no inputs were provided
    if not args.inputs:
        if not args.list_targets and not args.list_services:
            err_exit('no inputs were provided')
        else:
            sys.exit(0)

    # Check existence of the db_dir directory
    if not os.path.isdir(args.db_dir):
        err_exit('no such directory for --db-dir: %s', args.db_dir)
    db_dir = os.path.abspath(args.db_dir)

    # Now that path handling has been done, and all file references made,
    # we can safely change the base working directory to out-dir.
    try:
        os.makedirs(args.out_dir, exist_ok=True)
        os.chdir(args.out_dir)
    except Exception as e:
        err_exit('error creating or changing to --out-dir %s: %s', args.out_dir, str(e))

    # Set up the Workflow execution
    blackboard = QAAPBlackboard(args.verbose)
    blackboard.start_run(SERVICE, VERSION, vars(args))
    blackboard.put_miseq_run_dir(miseq_run_dir)
    blackboard.put_db_dir(db_dir)

    # Set the workflow params based on user inputs present
    params = list()
    if fastas:
        params.append(Params.FASTAS)
        blackboard.put_fastas(fastas)
    if single_fqs:
        params.append(Params.READS)
        blackboard.put_single_fqs(single_fqs)
    if paired_fqs:
        params.append(Params.READS)
        blackboard.put_paired_fqs(paired_fqs)
    if reference:
        params.append(Params.REFERENCE)
        blackboard.put_reference_path(reference)

    # Set up the workflow executor and run the workflow
    workflow = Workflow(DEPENDENCIES, params, targets, excludes)
    scheduler = SubprocessScheduler(args.max_cpus, args.max_mem, args.max_disc, args.max_time, args.poll, not args.verbose)
    executor = Executor(workflow, SERVICES, scheduler)
    executor.execute(blackboard, 42)

    # When done run MultiQC (unless excluded by user)
    multiqc = Executor(Workflow(DEPENDENCIES, params, [SystemTargets.MULTIQC], excludes), SERVICES, scheduler)
    multiqc.execute(blackboard, 99)

    # DONE, mark the end of the run end on the blackboard
    blackboard.end_run(workflow.status.value)

    # Dump the blackboard to the JSON results file
    with open('qaap-results.json', 'w') as f_json:
        json.dump(blackboard.as_dict(args.verbose), f_json)

    # Write a TSV summary?
    with open('qaap-summary.tsv', 'w') as f_tsv:
        commasep = lambda l: ','.join(l) if l else ''
        b = blackboard
        d = dict({
            's_id': 'TDOD',
            'n_reads': b.get('services/ReadsMetrics/results/n_reads', 'NA'),
            'nt_read': b.get('services/ReadsMetrics/results/n_bases', 'NA'),
            'pct_q30': b.get('services/ReadsMetrics/results/pct_q30', 'NA'),
            'n_ctgs': b.get('services/ContigsMetrics/results/n_seqs', 'NA'),
            'nt_ctgs': b.get('services/ContigsMetrics/results/tot_len', 'NA'),
            'n1':  b.get('services/ContigsMetrics/results/max_len', 'NA'),
            'n50':  b.get('services/ContigsMetrics/results/n50', 'NA'),
            'l50':  b.get('services/ContigsMetrics/results/l50', 'NA'),
            'pct_gc':  b.get('services/ContigsMetrics/results/pct_gc', b.get('services/ReadsMetrics/results/pct_gc', 'NA')),
            })
        print('\t'.join(d.keys()), file=f_tsv)
        print('\t'.join(map(lambda v: v if v else '', d.values())), file=f_tsv)

    # Done done
    return 0


if __name__ == '__main__':
   main()

